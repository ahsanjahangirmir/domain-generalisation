{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Color Bias Of Clip-ViT-Base "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Color Bias\n",
    "\n",
    "$$\n",
    "\\text{Color Bias} = \\frac{\\text{Color Accuracy}}{\\text{Total Accuracy}}\n",
    "$$\n",
    "\n",
    "Color Bias is overlliance of the model to rely on color instead of other features such as shape or texture to make predictions. We will use two datasets, the MNIST AND colored MNIST dataset to do that today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make All Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the CLIP Model and Processor. The Model that we will be using is \"openai/clip-vit-base-patch32\". We will also have processor which processes the image and text data required by CLIP-ViT-Base. We also move the model to GPU if available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load In the MNIST Dataset and apply any transformations needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.Resize((224, 224)),  \n",
    "                                 transforms.Grayscale(num_output_channels=3),  \n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                                      std=[0.229, 0.224, 0.225]),\n",
    "                             ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the dataloader which splits the dataset into batches and the classnames for the MNIST Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataloader = DataLoader(mnist_test, batch_size=128, shuffle=False)\n",
    "\n",
    "mnist_classes = [str(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function For zero shot image classification - Calculating Total Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_classification(model, processor, dataloader, device):\n",
    "    text_inputs = processor(text=mnist_classes, return_tensors=\"pt\", padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.get_text_features(**text_inputs)\n",
    "\n",
    "    correct_predictions = 0\n",
    "    total_images = 0\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    for images, labels in tqdm(dataloader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_features = model.get_image_features(images)\n",
    "\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)  \n",
    "\n",
    "        predicted_class = similarity.argmax(dim=1)\n",
    "\n",
    "        correct_predictions += (predicted_class == labels).sum().item()\n",
    "        total_images += labels.size(0)\n",
    "\n",
    "    accuracy = correct_predictions / total_images\n",
    "    print(f\"Total accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Call to Calculate and report Total Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [17:27<00:00, 13.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 32.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Total_Accuracy = zero_shot_classification(model, processor, mnist_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we Move On To get the Color Accuracy. The First step is to get and load in the Colorized MNIST Dataset. The following code helps to load in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorizedMNISTDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for idx, category in enumerate(mnist_classes):\n",
    "            category_dir = os.path.join(root_dir, category)\n",
    "            \n",
    "            for img_file in os.listdir(category_dir):\n",
    "                if img_file.endswith(('.png', '.jpg', '.jpeg')):  \n",
    "                    img_path = os.path.join(category_dir, img_file)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(idx)  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the necessary transformations that need to be applied onto the dataset such as resizing and converting to tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),  \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the Colorized MNIST Dataset and break it down into batches by sending it dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './Colorized_MNIST'\n",
    "colorized_mnist_dataset = ColorizedMNISTDataset(root_dir=root_dir, transform=transform)\n",
    "colorized_mnist_dataloader = DataLoader(colorized_mnist_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Calculate Zero-Shot Accuracy on Colorized MNIST Dataset the function is defined below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_classification(model, processor, dataloader, device):\n",
    "    text_inputs = processor(text=mnist_classes, return_tensors=\"pt\", padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.get_text_features(**text_inputs)\n",
    "\n",
    "    correct_predictions = 0\n",
    "    total_images = 0\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    for images, labels in tqdm(dataloader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_features = model.get_image_features(images)\n",
    "\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1) \n",
    "\n",
    "        predicted_class = similarity.argmax(dim=1)\n",
    "\n",
    "        correct_predictions += (predicted_class == labels).sum().item()\n",
    "        total_images += labels.size(0)\n",
    "\n",
    "    accuracy = correct_predictions / total_images\n",
    "    print(f\"Zero-shot accuracy on Colorized MNIST: {accuracy:.3f}%\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to Get Total Accuracy we can do the following "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [16:55<00:00,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot accuracy on Colorized MNIST: 0.259%\n",
      "Total Accuracy is : 25.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Color_accuracy = zero_shot_classification(model, processor, colorized_mnist_dataloader, device)\n",
    "print(f\"Total Accuracy is : {(Color_accuracy)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So As we remeber color Bias is :\n",
    "\n",
    "$$\n",
    "\\text{Color Bias} = \\frac{\\text{Color Accuracy}}{\\text{Total Accuracy}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Bias is : 79.15%\n"
     ]
    }
   ],
   "source": [
    "Color_Bias = Color_accuracy/Total_Accuracy\n",
    "\n",
    "print(f\"Color Bias is : {(Color_Bias)*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
